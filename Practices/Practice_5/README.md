# Gradient-Boosted Tree (GBT) Classifier
It's a machine learning technique used for regression analysis and for statistical classification problems, which produces a predictive model in the form of a set of weak prediction models, usually decision trees. GBT builds trees one by one, where each new tree helps correct mistakes made by a previously trained tree.

## Steps:  
### 1. Import libraries.
~~~
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.{GBTClassificationModel, GBTClassifier}
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}
~~~

### 2. Import a Spark Session.  
~~~
import org.apache.spark.sql.SparkSession
~~~

### 3. Use the Error reporting code.
~~~
import org.apache.log4j._
Logger.getLogger("org").setLevel(Level.ERROR)
~~~
> It's used to reduce the errors displayed in the console during the execution of the code.

### 4. Create a Spark session.  
~~~
  def main(): Unit = {
    val spark = SparkSession.builder.appName("GradientBoostedTreeClassifierExample").getOrCreate()
~~~
> A Spark session is created, and "GradientBoostedTreeClassifierExample" is assigned as the application name.  

### 5.  Load and parse the data file, converting it to a DataFrame.
* Print the schema.
~~~
    val data = spark.read.format("libsvm").load("sample_libsvm_data.txt")
    data.printSchema()
~~~
>  The dataset is loaded from the file "sample_libsvm_data.txt", and the schema of the data is printed. 

### 6. Index labels, adding metadata to the label column.  
* Fit on whole dataset to include all labels in index.
~~~
    val labelIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(data)
~~~
> The labels are indexed in the "label" column, metadata is added to change the values ​​from string type to numeric type and it is adjusted to the dataset (data). 

### 7. Automatically identify categorical features, and index them.
* Set maxCategories so features with > 4 distinct values are treated as continuous.
~~~
    val featureIndexer = new VectorIndexer().setInputCol("features").setOutputCol("indexedFeatures").setMaxCategories(4).fit(data)
~~~
> The features column is indexed, and a limit of 4 categories is established, so that from this the data is treated as continuous. Changes to the dataset (data) are also adjusted.

### 8. Split the data into training and test sets.
~~~
    val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))
~~~
> The data is divided into 70% training and 30% testing.  

### 9. Train a GBT model.  
~~~
    val gbt = new GBTClassifier().setLabelCol("indexedLabel").setFeaturesCol("indexedFeatures").setMaxIter(10).setFeatureSubsetStrategy("auto")
~~~

> The model is trained with the `GBTClassifier ()` function.
> The indexed columns are used, and a maximum of 10 iterations are indicated for the execution of the model 

### 10. Convert indexed labels back to original labels.  
~~~
    val labelConverter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(labelIndexer.labels)
~~~
> The indexed labels are converted back to their original values, with the `IndexToString ()` function.

### 11. Chain indexers and GBT in a Pipeline.  
~~~
    val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, gbt, labelConverter))
~~~
> The indexers, the model (gbt) and the labelConverter variable are attached inside the pipeline.

### 12. Train model. 
~~~
    val model = pipeline.fit(trainingData)
~~~
> The model is trained and adjusted to the training data.

### 13. Make predictions.  
~~~
    val predictions = model.transform(testData)
~~~
> Model predictions are made and fit the test data.

### 14. Select example rows to display.  
~~~
    predictions.select("predictedLabel", "label", "features").show(5)
~~~
> The columns "predictedLabel", "label" and "features" are selected to display the first 5 rows of the predictions made by the model.

### 15. Select (prediction, true label) and compute test error.  
~~~
    val evaluator = new MulticlassClassificationEvaluator().setLabelCol("indexedLabel").setPredictionCol("prediction").setMetricName("accuracy")

    val accuracy = evaluator.evaluate(predictions)
    println(s"Test Error = ${1.0 - accuracy}")
~~~
> The model's level of accuracy is calculated with the `evaluate` function, and using the result the error percentage is calculated with the subtraction: 1.0 - level of accuracy.


### 16. Print result of Trees using GBT (10).
~~~
    val gbtModel = model.stages(2).asInstanceOf[GBTClassificationModel]
    println(s"Learned classification GBT model:\n ${gbtModel.toDebugString}")

    spark.stop()
  }

main()
~~~
> All the trees generated by the model are printed, in this case 10 in total, including the conditions and the results of the predictions for each of its branches.
> The model showed an approximate 3% error, which leaves us with an accuracy level of approximately 97%; This means that the model works very well and the predictions it makes are quite reliable.

