# Decision Tree Classifier  
Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks. The goal is to create a model that predicts the value of a target variable by learning simple decision rules inferred from the data features.  

## Steps:  
### 1. Import libraries.
~~~
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.DecisionTreeClassificationModel
import org.apache.spark.ml.classification.DecisionTreeClassifier
import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator
import org.apache.spark.ml.feature.{IndexToString, StringIndexer, VectorIndexer}
~~~
> Libraries were imported to use Pipeline, IndexToString, StringIndexer, VectorIndexer, and those that correspond to the decision tree classifier: DecisionTreeClassificationModel and DecisionTreeClassifier.  

### 2. Import a Spark Session.  
~~~
import org.apache.spark.sql.SparkSession
~~~

### 3. Create a Spark session.  
~~~
  def main(): Unit = {
    val spark = SparkSession.builder.appName("DecisionTreeClassificationExample").getOrCreate()
~~~
> A new Spark session is created, and the application is named: "DecisionTreeClassificationExample".

### 4.  Load the data stored in LIBSVM format as a DataFrame.  
~~~
    val data = spark.read.format("libsvm").load("sample_libsvm_data.txt")
~~~

### 5. Index labels, adding metadata to the label column.  
* Fit on whole dataset to include all labels in index.
~~~
    val labelIndexer = new StringIndexer().setInputCol("label").setOutputCol("indexedLabel").fit(data)
~~~

> The labels are indexed and metadata is added so that the text-type values are converted to numerical values.
> Tags are included in the index by wrapping throughout the dataset (data). 

### 6. Automatically identify categorical features, and index them.
* Set maxCategories so features with > 4 distinct values are treated as continuous.
~~~
    val featureIndexer = new VectorIndexer().setInputCol("features").setOutputCol("indexedFeatures").setMaxCategories(4).fit(data)
~~~

### 7. Split the data into training and test sets.
* Split the data using random split into 70% for traingin and 30% held out for testing.  
~~~
    val Array(trainingData, testData) = data.randomSplit(Array(0.7, 0.3))
~~~

### 8. Train a DecisionTree model.  
~~~
    val dt = new DecisionTreeClassifier().setLabelCol("indexedLabel").setFeaturesCol("indexedFeatures")
~~~
> The model is trained using DecisionTreeClassifier () and, pointing out the columns for the label and the features. 

### 9. Convert indexed labels back to original labels.  
~~~
    val labelConverter = new IndexToString().setInputCol("prediction").setOutputCol("predictedLabel").setLabels(labelIndexer.labels)
~~~
> The columns 'labelIndexer' and 'labels' are taken, to return the original values ​​of the labels indexed within the columns 'prediction' and 'predictedLabel

### 10. Chain indexers and tree in a Pipeline.  
~~~
    val pipeline = new Pipeline().setStages(Array(labelIndexer, featureIndexer, dt, labelConverter))
~~~

### 11. Train model. 
~~~
    val model = pipeline.fit(trainingData)
~~~
> The model fits the training data.

### 12. Make predictions.  
~~~
    val predictions = model.transform(testData)
~~~
>  Model predictions are calculated, transforming training data into test data.

### 13. Select example rows to display.  
~~~
    predictions.select("predictedLabel", "label", "features").show(5)
~~~
> The columns 'predictedLabel', 'label' and 'features' are selected to display in console the first 5 rows of the predictions calculated by the model.

### 14. Select (prediction, true label) and compute test error.  
~~~
    val evaluator = new MulticlassClassificationEvaluator().setLabelCol("indexedLabel").setPredictionCol("prediction").setMetricName("accuracy")
    val accuracy = evaluator.evaluate(predictions)
    println(s"Test Error = ${(1.0 - accuracy)}")
~~~
> `Evaluate` is used to calculate the level of accuracy of the predictions made by the model.
> This same figure is used to obtain the model error percentage, by subtracting: 1.0 minus the level of accuracy.  

### 15. Print the tree obtained from the model.
~~~
    val treeModel = model.stages(2).asInstanceOf[DecisionTreeClassificationModel]
    println(s"Learned classification tree model:\n ${treeModel.toDebugString}")

    spark.stop()
  }

main()
~~~
> The tree generated by the model is shown in full; The decisions used and the prediction results obtained for each branch appear in it. The depth level and the number of resulting nodes are also mentioned.
> In this case, a `Test Error = 0.02564102564102566` was obtained, which would leave us with approximately 98% accuracy, meaning that the model works quite well. 
