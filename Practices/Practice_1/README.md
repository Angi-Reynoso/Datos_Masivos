
# LINEAR REGRESSION PRACTICE 

## First Stepts

**1. Import LinearRegression**  
~~~
import org.apache.spark.ml.regression.LinearRegression
~~~

**2. Optional: Use the following code to configure errors**  
~~~
import org.apache.log4j._
Logger.getLogger("org").setLevel(Level.ERROR)
~~~
>`log4j._` It is an additional library that allows our application to display information messages about what is happening in it.  
>`getLogger`It is a method of a Logger class used find or create a logger.  

**3. Start a simple Spark Session**  
~~~
import org.apache.spark.sql.SparkSession
val spark = SparkSession.builder().getOrCreate()
~~~  
> The entry point into all functionality in Spark is the `SparkSession` class. To create a basic SparkSession, just use `SparkSession.builder()`.  

**4. Use Spark for the Clean-Ecommerce csv file** 
~~~
val data  = spark.read.option("header","true").option("inferSchema", "true").format("csv").load("Clean-Ecommerce.csv")
~~~  
> First declare a variable (df) to which the file to be loaded will be assigned.  
>  * `spark.read` is used to load a CSV file into Spark.  
>  * `.option ("header", "true")` is used to load file headers.  
>  * `.option ("inferSchema", "true")` helps Spark automatically infer data types from the file.  

> And finally in `csv("")` we put the name of the file and its extension, in this case _"Clean-Ecommerce.csv"_.  

**5. Print the schema on the DataFrame**  
~~~
data.printSchema
~~~  
> `printSchema()` is used to display only existing columns and information about them.  

**6. Print an example row from the DataFrame**  
~~~
data.head(1)
val colnames = data.columns
val firstrow = data.head(1)(0)
println("\n")
println("Example data row")
for(ind <- Range(0, colnames.length)){
    println(colnames(ind))
    println(firstrow(ind))
    println("\n")
}
~~~  
> `head()` is used to display the first N elements of the DataFrame.  

<br>

## Set up the DataFrame for Machine Learning

**7. Transform the data frame so that it takes the form of ("label", "features")**  
* Import VectorAssembler and Vectors:  
~~~
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors
~~~  
> `VectorAssembler` is a transformer that combines a given list of columns into a single vector column. It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees.  

> Factory methods for `org.apache.spark.ml.linalg.Vector`. We don't use the name `Vector` because Scala imports `scala.collection.immutable.Vector` by default.  

**8. Rename the Yearly Amount Spent column as "label"**  
* Also from the data take only the numerical column.      
* Leave all this as a new DataFrame called df.  
~~~
val df = data.select(data("Yearly Amount Spent").as("label"), $"Avg Session Length", $"Time on App", $"Time on Website", $"Length of Membership", $"Yearly Amount Spent")
~~~  

**9. The VectorAssembler Object**  
* Use this object to convert the input columns of the df to a single output column of an array named "features" (`.setOutputCol`).  
* Configure the input columns from where we are supposed to read the values (`.setInputCols`).  
* Call this a new assambler.  
~~~
val new_assembler = new VectorAssembler().setInputCols(Array("Avg Session Length", "Time on App", "Time on Website", "Length of Membership", "Yearly Amount Spent")).setOutputCol("features")
~~~  

**10. Use the assembler to transform our DataFrame to two columns: label and features**  
~~~
val output = new_assembler.transform(df).select($"label",$"features")
~~~  
> `new_assembler.transform()` it allows to scaling, converting, or modifying features.  

**11. Create an object for line regression model**  
~~~
val lr = new LinearRegression()
~~~  
> `LinearRegression()` is the constructor that is used for the LinearRegression class.

**12. Fit the model for the data and call this model lrModel**  
~~~
val lrModel = lr.fit(output)
~~~
> `fit()` is a method implemented by an Estimator, which accepts a DataFrame and produces a Model, which is a Transformer.  

**13. Print the coefficients and intercept for the linear regression**  
~~~
println(s"Coefficients: ${lrModel.coefficients} Intercept: ${lrModel.intercept}")
~~~  
> The regression _coefficients_ represent the mean changes in the response variable for one unit of change in the predictor variable while holding the other predictors in the model constant.  

> _Intercept_, also known as the y-intercept, it is simply the value at which the fitted line crosses the y-axis in linear regression analysis.  

**14. Summarize the model on the training set and print the output of some metrics**  
* Use our model's .summary method to create an object called trainingSummary.  
~~~
val trainingSummary = lrModel.summary
~~~  
> `summary` it's used to calculate and obtain statistics.  

**15. Show the residuals values, the RMSE, the MSE, and also the R^2**  
~~~
trainingSummary.residuals.show()
val RMSE = trainingSummary.rootMeanSquaredError
val MSE = scala.math.pow(RMSE, 2.0)
val R2 = trainingSummary.r2
~~~
> `residuals` is the diferrence between the label and predicted value.  

> `rootMeanSquareError` returns the root mean squared error, which is defined as the square root of the mean squared error.  

> `pow` returns the value of the first argument raised to the power of the second argument.  
>   * The _Mean Squared Error (MSE)_ tells you how close a regression line is to a set of points. It does this by taking the distances from the points to the regression line (these distances are the “errors”) and squaring them. The squaring is necessary to remove any negative signs. It also gives more weight to larger differences. It’s called the mean squared error as you’re finding the average of a set of errors.  

> `r2` The coefficient of determination; a mesure of fit.  

